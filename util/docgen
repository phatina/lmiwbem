#!/usr/bin/python
# ##### BEGIN LICENSE BLOCK #####
#
#   Copyright (C) 2014-2015, Peter Hatina <phatina@redhat.com>
#
#   This library is free software; you can redistribute it and/or modify
#   it under the terms of the GNU Lesser General Public License as
#   published by the Free Software Foundation, either version 2.1 of the
#   License, or (at your option) any later version.
#
#   This library is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#   GNU Lesser General Public License for more details.
#
#   You should have received a copy of the GNU Lesser General Public
#   License along with this program; if not, write to the Free Software
#   Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
#   MA 02110-1301 USA
#
# ##### END LICENSE BLOCK #####

'''
Doc string generator for LMIWBEM.  Generator reads input file with doc strings
descriptions and generates a C/C++ header file with macros for every doc
string.

Sample input:
    # Doc string for Class.Method_A
    Class_Method_A = {
        ...
        doc string
        ...
    }

    # Doc string for Class.Method_B
    Class_Method_B = {
        ...
        doc string
        ...
    }


Sample output:
    // Generated by LMIWBEM's docgen

    #ifndef   TEST_H
    #  define TEST_H

    #  define docstr_Class_Method_A \
              "    ...\n" \
              "    doc string\n" \
              "    ...\n"

    #  define docstr_Class_Method_B \
              "    ...\n" \
              "    doc string\n" \
              "    ...\n"

    #endif // TEST_H

Usage:
    docgen.py input.pydoc output.h
'''

import collections
import os
import sys


class LexicalError(Exception):
    pass


class SyntaxError(Exception):
    pass


class Token(object):
    '''
    Token class
    '''
    T_EOF, \
    T_LEX_ERROR, \
    T_IDENT, \
    T_OPEN_BRACE, \
    T_CLOSE_BRACE, \
    T_EQUAL, \
    T_DOCSTR = range(7)

    def __init__(self, type, value=None, lineno=None):
        self.type = type
        self.value = value
        self.lineno = lineno

    def __repr__(self):
        if self.type == self.T_EOF:
            return 'T_EOF'
        elif self.type == self.T_LEX_ERROR:
            return 'T_LEX_ERROR: %s at %d' % (self.value, self.lineno)
        elif self.type == self.T_SYN_ERROR:
            return 'T_SYN_ERROR: %s at %d' % (self.value, self.lineno)
        elif self.type == self.T_IDENT:
            return 'T_IDENT: \'%s\'' % self.value
        elif self.type == self.T_OPEN_BRACE:
            return 'T_OPEN_BRACE'
        elif self.type == self.T_CLOSE_BRACE:
            return 'T_CLOSE_BRACE'
        elif self.type == self.T_EQUAL:
            return 'T_EQUAL'
        elif self.type == self.T_DOCSTR:
            return 'T_DOCSTR'
        else:
            return 'UNKNOWN TOKEN'


class Scanner(object):
    '''
    Simple scanner for custom language describing doc strings for Boost::Python
    classes.
    '''
    S_INIT, \
    S_IDENT, \
    S_DOCSTR = range(3)

    def __init__(self, input_file):
        self.fin = open(input_file, 'r')
        self.state = self.S_INIT
        self.unget = None
        self.lineno = 1

    @staticmethod
    def is_ident_begin(c):
        return c.isalpha() or c == '_'

    @staticmethod
    def is_ident_cont(c):
        return c.isalnum() or c == '_'

    @staticmethod
    def is_whitespace(c):
        return c in ' \r\n'

    @staticmethod
    def is_new_line(c):
        return c == '\n'

    @staticmethod
    def is_eof(c):
        return c == ''

    def close(self):
        self.fin.close()

    def getchar(self):
        if self.unget is not None:
            c = self.unget
            self.unget = None
            rval = c
        else:
            rval = self.fin.read(1)
            if self.is_new_line(rval):
                self.lineno +=1

        return rval

    def ungetchar(self, c):
        self.unget = c

    def skip_whitespace(self):
        c = self.getchar()
        while self.is_whitespace(c):
            c = self.getchar()
        self.ungetchar(c)

    def get_next_token(self):
        value = ''
        lineno = self.lineno
        while True:
            c = self.getchar()

            #
            # Finite automata
            #
            if self.state == self.S_INIT:
                #
                # Initial state
                #
                if self.is_ident_begin(c):
                    self.state = self.S_IDENT
                    value += c
                elif c == '#':
                    while c != '\n':
                        c = self.getchar()
                elif c == '{':
                    self.state = self.S_DOCSTR
                    self.skip_whitespace()
                    return Token(Token.T_OPEN_BRACE)
                elif c == '}':
                    return Token(Token.T_CLOSE_BRACE)
                elif c == '=':
                    return Token(Token.T_EQUAL)
                elif self.is_eof(c):
                    return Token(Token.T_EOF)
                elif self.is_whitespace(c):
                    continue
                else:
                    return Token(
                        Token.T_LEX_ERROR,
                        'Unexpected symbol: \'%s\'' % c,
                        lineno)
            elif self.state == self.S_IDENT:
                #
                # Identifier state
                #
                if self.is_ident_cont(c):
                    value += c
                else:
                    self.ungetchar(c)
                    self.state = self.S_INIT
                    return Token(Token.T_IDENT, value)
            elif self.state == self.S_DOCSTR:
                #
                # Docstring state
                #
                if c == '\\':
                    c = self.getchar()
                    if c in '{}#\\"':
                        value += c
                    elif self.is_new_line(c):
                        continue
                    else:
                        self.state = self.S_INIT
                        return Token(
                            Token.T_LEX_ERROR,
                            'Unknown escape sequence: \'\\%s\'' % c,
                            self.lineno)
                elif c == '{':
                    self.state = self.S_INIT
                    return Token(
                        Token.T_LEX_ERROR,
                        'Unexpected open brace',
                        self.lineno)
                elif c == '}':
                    self.ungetchar(c)
                    self.state = self.S_INIT
                    return Token(Token.T_DOCSTR, value)
                elif c == '"':
                    self.state = self.S_INIT
                    return Token(
                        Token.T_LEX_ERROR,
                        'Unexpected quotes',
                        self.lineno)
                elif self.is_eof(c):
                    self.state = self.S_INIT
                    return Token(
                        Token.T_LEX_ERROR,
                        'Unclosed doc string',
                        lineno)
                else:
                    value += c
            else:
                raise ValueError('Unknown state')


class Parser(object):
    '''
    PyDoc parser class.
    '''
    def __init__(self, input_file):
        self.scanner = Scanner(input_file)
        self.doc_strings = collections.OrderedDict()

    @staticmethod
    def token_ok_for_parse(token):
        return token.type not in (
            Token.T_EOF,
            Token.T_LEX_ERROR,
            Token.T_SYN_ERROR)

    def check_token_type(self, t, t_type, errorstr):
        if t.type == Token.T_LEX_ERROR:
            raise LexicalError(t.value, t.lineno)
        if t.type != t_type:
            raise SyntaxError(errorstr, self.scanner.lineno)

    def parse_docstring(self):
        # Do we have anything to parse?
        t = self.scanner.get_next_token()
        if t.type == Token.T_EOF:
            return None, None

        # IDENTIFIER
        self.check_token_type(t, Token.T_IDENT, 'Identifier excepcted')

        ident = t.value

        # EQUAL
        t = self.scanner.get_next_token()
        self.check_token_type(t, Token.T_EQUAL, 'Equal symbol expected')

        # OPEN BRACE
        t = self.scanner.get_next_token()
        self.check_token_type(t, Token.T_OPEN_BRACE, 'Open bracelet expected')

        # DOC STRING
        t = self.scanner.get_next_token()
        self.check_token_type(t, Token.T_DOCSTR, 'Doc string expected')

        doc_string = t.value

        # CLOSE BRACE
        t = self.scanner.get_next_token()
        self.check_token_type(t, Token.T_CLOSE_BRACE, 'Close bracelet expected')

        return ident, doc_string

    def parse(self):
        try:
            while True:
                ident, doc_string = self.parse_docstring()
                if ident is None and doc_string is None:
                    break
                self.doc_strings[ident] = doc_string
        except Exception:
            raise
        finally:
            self.scanner.close()
        return self.doc_strings


class Generator(object):
    '''
    PyDoc to C++ generator.
    '''
    def __init__(self, doc_strings):
        self.doc_strings = doc_strings
        self.fout = None

    def generate_include_guard_name(self):
        filename = os.path.basename(self.fout.name)
        return filename.upper().replace('.', '_')

    def generate_header(self):
        self.fout.write('// Generated by LMIWBEM\'s %s\n\n' % os.path.basename(sys.argv[0]))

        # Guard
        guard = self.generate_include_guard_name()
        self.fout.write('#ifndef   %s\n' % guard)
        self.fout.write('#  define %s\n\n' % guard)

    def generate_footer(self):
        self.fout.write('#endif // %s\n' % self.generate_include_guard_name())

    def generate_doc_string(self, doc_string):
        assert self.fout is not None, 'generate() must precede'

        lines = doc_string.split('\n')
        while not lines[-1]:
            lines = lines[:-1]

        lines_len = len(lines)
        for i, line in enumerate(lines):
            self.fout.write('      "%s\\n"' % line)
            if i < lines_len - 1:
                self.fout.write(' \\')
            self.fout.write('\n')

    def generate(self, output_file):
        self.fout = open(output_file, 'w')
        self.generate_header()
        for ident, doc_string in self.doc_strings.iteritems():
            self.fout.write('#  define docstr_%s \\\n' % ident)
            self.generate_doc_string(doc_string)
            self.fout.write('\n')
        self.generate_footer()
        self.fout.close()



if __name__ == '__main__':
    if len(sys.argv) < 2:
        sys.stderr.write('Input filename missing!\n')
        sys.exit(1)
    elif len(sys.argv) < 3:
        sys.stderr.write('Output filename missing!\n')
        sys.exit(1)

    parser = Parser(sys.argv[1])

    try:
        doc_strings = parser.parse()
    except LexicalError as e:
        print 'Lexical error: %s at %d' % e.args
        sys.exit(2)
    except SyntaxError as e:
        print 'Syntax error: %s at %d' % e.args
        sys.exit(3)

    generator = Generator(doc_strings)
    generator.generate(sys.argv[2])
